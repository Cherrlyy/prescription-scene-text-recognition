{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU9gvCbrdJJW",
        "outputId": "54e1c9e8-a095-45bf-a34c-373c05ce9942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EasyOCR'...\n",
            "remote: Enumerating objects: 2736, done.\u001b[K\n",
            "remote: Total 2736 (delta 0), reused 0 (delta 0), pack-reused 2736\u001b[K\n",
            "Receiving objects: 100% (2736/2736), 157.83 MiB | 25.84 MiB/s, done.\n",
            "Resolving deltas: 100% (1664/1664), done.\n",
            "Updating files: 100% (313/313), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JaidedAI/EasyOCR.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./EasyOCR/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlYrDdhLdND2",
        "outputId": "7bf5dcaa-725d-45ac-b916-25c7fe21e936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 1)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 2)) (0.17.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 3)) (4.9.0.80)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 6)) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 7)) (0.19.3)\n",
            "Collecting python-bidi (from -r ./EasyOCR/requirements.txt (line 8))\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 9)) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from -r ./EasyOCR/requirements.txt (line 10)) (2.0.4)\n",
            "Collecting pyclipper (from -r ./EasyOCR/requirements.txt (line 11))\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from -r ./EasyOCR/requirements.txt (line 12))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r ./EasyOCR/requirements.txt (line 1)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r ./EasyOCR/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r ./EasyOCR/requirements.txt (line 7)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r ./EasyOCR/requirements.txt (line 7)) (2024.5.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r ./EasyOCR/requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r ./EasyOCR/requirements.txt (line 7)) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->-r ./EasyOCR/requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r ./EasyOCR/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r ./EasyOCR/requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"EasyOCR/user_network\"\n",
        "!mkdir \"EasyOCR/model\"\n",
        "!mkdir \"EasyOCR/newExamples\"\n",
        "!mkdir \"EasyOCR/preprocessedData\""
      ],
      "metadata": {
        "id": "cPYSmm7NdfgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EasyOCR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Sc7vAceBqw",
        "outputId": "1ff9bc41-a54f-4852-cc4c-927bc272dd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EasyOCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiGHErsfGe2T",
        "outputId": "da8c4cd0-ea7c-4bf2-95d0-e811c2c2e0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from easyocr.easyocr import *\n",
        "from PIL import Image\n",
        "\n",
        "# GPU 설정\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
        "\n",
        "\n",
        "def get_files(path):\n",
        "    file_list = []\n",
        "\n",
        "    files = [f for f in os.listdir(path) if not f.startswith('.')]  # skip hidden file\n",
        "    files.sort()\n",
        "    abspath = os.path.abspath(path)\n",
        "    for file in files:\n",
        "        file_path = os.path.join(abspath, file)\n",
        "        file_list.append(file_path)\n",
        "\n",
        "    return file_list, len(file_list)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # # Using default model\n",
        "    # reader = Reader(['ko'], gpu=True)\n",
        "\n",
        "    # Using custom model\n",
        "    #'/content/drive/MyDrive/Colab Notebooks/workspace/pre_trained_model/'\n",
        "    reader = Reader(['ko'], gpu=True,\n",
        "                    model_storage_directory='/content/drive/MyDrive/Colab Notebooks/workspace/pre_trained_model/',\n",
        "                    user_network_directory='./user_network',\n",
        "                    recog_network='custom')\n",
        "\n",
        "    files, count = get_files('./output')\n",
        "\n",
        "    for idx, file in enumerate(files):\n",
        "        filename = os.path.basename(file)\n",
        "        Image.MAX_IMAGE_PIXELS = None\n",
        "        result = reader.readtext(file)\n",
        "\n",
        "\n",
        "        # ./easyocr/utils.py 733 lines\n",
        "        # result[0]: bbox\n",
        "        # result[1]: string\n",
        "        # result[2]: confidence\n",
        "        for (bbox, string, confidence) in result:\n",
        "            print(\"filename: '%s', confidence: %.4f, string: '%s'\" % (filename, confidence, string))\n",
        "            # print('bbox: ', bbox)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjujMHfZd-UZ",
        "outputId": "9cf891e1-c5b4-461f-a77d-c581cdd91982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename: '1.jpg', confidence: 0.2722, string: '여쭈'\n",
            "filename: '10.jpg', confidence: 0.1319, string: '잇'\n",
            "filename: '10.jpg', confidence: 0.9156, string: '1'\n",
            "filename: '100.jpg', confidence: 0.7462, string: '같이'\n",
            "filename: '101.jpg', confidence: 0.5100, string: '용히지'\n",
            "filename: '102.jpg', confidence: 0.4853, string: '마쎄요'\n",
            "filename: '103.jpg', confidence: 0.9287, string: '제된'\n",
            "filename: '104.jpg', confidence: 0.9911, string: '악은'\n",
            "filename: '105.jpg', confidence: 0.7996, string: '법'\n",
            "filename: '106.jpg', confidence: 0.1903, string: '랑메'\n",
            "filename: '107.jpg', confidence: 0.5043, string: '기재된'\n",
            "filename: '108.jpg', confidence: 0.9954, string: '따'\n",
            "filename: '109.jpg', confidence: 0.3217, string: '처빵기간'\n",
            "filename: '11.jpg', confidence: 0.0403, string: '젠년윽'\n",
            "filename: '110.jpg', confidence: 0.3969, string: '브요하'\n",
            "filename: '112.jpg', confidence: 0.5107, string: '하세요'\n",
            "filename: '113.jpg', confidence: 0.9991, string: '내'\n",
            "filename: '114.jpg', confidence: 0.0282, string: '아껴워'\n",
            "filename: '115.jpg', confidence: 0.0633, string: '비불'\n",
            "filename: '116.jpg', confidence: 0.8024, string: '쟁'\n",
            "filename: '117.jpg', confidence: 0.3896, string: '볶히'\n",
            "filename: '118.jpg', confidence: 0.0399, string: '에제'\n",
            "filename: '119.jpg', confidence: 0.1185, string: '하'\n",
            "filename: '12.jpg', confidence: 0.0248, string: '츠'\n",
            "filename: '120.jpg', confidence: 0.0297, string: '단쟁'\n",
            "filename: '121.jpg', confidence: 0.2657, string: '라포경'\n",
            "filename: '122.jpg', confidence: 0.9798, string: '리'\n",
            "filename: '123.jpg', confidence: 0.1633, string: '그램'\n",
            "filename: '124.jpg', confidence: 0.0791, string: '무빠빠경'\n",
            "filename: '125.jpg', confidence: 0.0167, string: '비정'\n",
            "filename: '126.jpg', confidence: 0.6737, string: '내'\n",
            "filename: '127.jpg', confidence: 0.7796, string: '사람'\n",
            "filename: '129.jpg', confidence: 0.0967, string: '서든 버내'\n",
            "filename: '13.jpg', confidence: 0.9020, string: '년'\n",
            "filename: '130.jpg', confidence: 0.1293, string: '우이밟딩'\n",
            "filename: '133.jpg', confidence: 0.3735, string: '캐'\n",
            "filename: '134.jpg', confidence: 0.9092, string: '455'\n",
            "filename: '135.jpg', confidence: 0.5343, string: '00'\n",
            "filename: '136.jpg', confidence: 0.0596, string: '1g'\n",
            "filename: '137.jpg', confidence: 0.9019, string: '5450'\n",
            "filename: '138.jpg', confidence: 0.7851, string: '가'\n",
            "filename: '14.jpg', confidence: 0.8860, string: '조자'\n",
            "filename: '141.jpg', confidence: 0.0233, string: 'H'\n",
            "filename: '142.jpg', confidence: 0.1540, string: '064'\n",
            "filename: '143.jpg', confidence: 0.4934, string: '556'\n",
            "filename: '144.jpg', confidence: 0.1818, string: '찌'\n",
            "filename: '146.jpg', confidence: 0.3458, string: '몽'\n",
            "filename: '147.jpg', confidence: 0.0748, string: '빼와'\n",
            "filename: '15.jpg', confidence: 0.1240, string: '환지동'\n",
            "filename: '16.jpg', confidence: 0.1305, string: '야'\n",
            "filename: '17.jpg', confidence: 0.1812, string: '야규'\n",
            "filename: '17.jpg', confidence: 0.7756, string: '680'\n",
            "filename: '19.jpg', confidence: 0.0309, string: '갑'\n",
            "filename: '2.jpg', confidence: 0.1222, string: '복얗아'\n",
            "filename: '20.jpg', confidence: 0.5179, string: '저녁'\n",
            "filename: '21.jpg', confidence: 0.4958, string: '임뷰'\n",
            "filename: '22.jpg', confidence: 0.7102, string: '점심'\n",
            "filename: '23.jpg', confidence: 0.9093, string: '아침'\n",
            "filename: '24.jpg', confidence: 0.0453, string: '승'\n",
            "filename: '25.jpg', confidence: 0.4965, string: '끼'\n",
            "filename: '27.jpg', confidence: 0.7591, string: '취침'\n",
            "filename: '28.jpg', confidence: 0.0703, string: '식전'\n",
            "filename: '29.jpg', confidence: 0.9540, string: '포'\n",
            "filename: '3.jpg', confidence: 0.0676, string: '략제'\n",
            "filename: '30.jpg', confidence: 0.1710, string: '점씩'\n",
            "filename: '32.jpg', confidence: 0.0852, string: '아껴워'\n",
            "filename: '34.jpg', confidence: 0.0199, string: '키a하'\n",
            "filename: '35.jpg', confidence: 0.2530, string: '소염지켜제'\n",
            "filename: '36.jpg', confidence: 0.1124, string: '츠'\n",
            "filename: '37.jpg', confidence: 0.8778, string: '약'\n",
            "filename: '38.jpg', confidence: 0.9014, string: '나타수'\n",
            "filename: '39.jpg', confidence: 0.7799, string: '있어요'\n",
            "filename: '40.jpg', confidence: 0.9416, string: '임산부임'\n",
            "filename: '41.jpg', confidence: 0.7067, string: '계획이'\n",
            "filename: '42.jpg', confidence: 0.3029, string: '얘가'\n",
            "filename: '43.jpg', confidence: 0.0357, string: '워'\n",
            "filename: '44.jpg', confidence: 0.7327, string: '있는'\n",
            "filename: '45.jpg', confidence: 0.1191, string: '늄성든'\n",
            "filename: '46.jpg', confidence: 0.0431, string: '브드'\n",
            "filename: '46.jpg', confidence: 0.7996, string: '미리'\n",
            "filename: '47.jpg', confidence: 0.8630, string: '시'\n",
            "filename: '47.jpg', confidence: 0.0460, string: '칼셋'\n",
            "filename: '47.jpg', confidence: 0.4543, string: '해세요'\n",
            "filename: '48.jpg', confidence: 0.0663, string: '에씌니'\n",
            "filename: '49.jpg', confidence: 0.0945, string: '징하'\n",
            "filename: '5.jpg', confidence: 0.1189, string: '서율올바른정형외'\n",
            "filename: '50.jpg', confidence: 0.9764, string: '1'\n",
            "filename: '50.jpg', confidence: 0.2393, string: '쟁'\n",
            "filename: '51.jpg', confidence: 0.1834, string: '악표'\n",
            "filename: '52.jpg', confidence: 0.4667, string: '이원제'\n",
            "filename: '54.jpg', confidence: 0.0950, string: '이버'\n",
            "filename: '54.jpg', confidence: 0.5499, string: '완제'\n",
            "filename: '55.jpg', confidence: 0.9247, string: '있든'\n",
            "filename: '56.jpg', confidence: 0.9319, string: '각'\n",
            "filename: '57.jpg', confidence: 0.4289, string: '주씩하요'\n",
            "filename: '58.jpg', confidence: 0.5812, string: '쩐'\n",
            "filename: '59.jpg', confidence: 0.0948, string: '오0'\n",
            "filename: '6.jpg', confidence: 0.9096, string: '일해'\n",
            "filename: '60.jpg', confidence: 0.0396, string: '크['\n",
            "filename: '60.jpg', confidence: 0.1222, string: '두여기간'\n",
            "filename: '62.jpg', confidence: 0.0000, string: ''\n",
            "filename: '63.jpg', confidence: 0.1825, string: '라프쟁'\n",
            "filename: '64.jpg', confidence: 0.5498, string: '그램'\n",
            "filename: '65.jpg', confidence: 0.4509, string: '써문'\n",
            "filename: '66.jpg', confidence: 0.2056, string: '악요'\n",
            "filename: '67.jpg', confidence: 0.4265, string: '소화성'\n",
            "filename: '68.jpg', confidence: 0.7899, string: ';'\n",
            "filename: '69.jpg', confidence: 0.2230, string: '느'\n",
            "filename: '69.jpg', confidence: 0.0406, string: '도'\n",
            "filename: '69.jpg', confidence: 0.2941, string: 'jC'\n",
            "filename: '70.jpg', confidence: 0.1142, string: '비디'\n",
            "filename: '70.jpg', confidence: 0.0735, string: '혜'\n",
            "filename: '70.jpg', confidence: 0.1748, string: '유인발딩'\n",
            "filename: '71.jpg', confidence: 0.0002, string: 'J등닫시요*'\n",
            "filename: '71.jpg', confidence: 0.0834, string: '1젯소생'\n",
            "filename: '72.jpg', confidence: 0.1356, string: '('\n",
            "filename: '72.jpg', confidence: 0.0392, string: 'U'\n",
            "filename: '72.jpg', confidence: 0.0772, string: ''ml'\n",
            "filename: '73.jpg', confidence: 0.2148, string: '생퓨양'\n",
            "filename: '74.jpg', confidence: 0.2515, string: '각도른'\n",
            "filename: '75.jpg', confidence: 0.4189, string: '갛애'\n",
            "filename: '76.jpg', confidence: 0.9626, string: '또는'\n",
            "filename: '77.jpg', confidence: 0.3834, string: '신장'\n",
            "filename: '78.jpg', confidence: 0.0062, string: '젊끈'\n",
            "filename: '78.jpg', confidence: 0.3763, string: '제'\n",
            "filename: '79.jpg', confidence: 0.0244, string: '꺼'\n",
            "filename: '79.jpg', confidence: 0.8966, string: '애'\n",
            "filename: '8.jpg', confidence: 0.0730, string: '죄액'\n",
            "filename: '80.jpg', confidence: 0.3126, string: '크'\n",
            "filename: '80.jpg', confidence: 0.2720, string: '냐'\n",
            "filename: '80.jpg', confidence: 0.3669, string: '에거'\n",
            "filename: '81.jpg', confidence: 0.9994, string: '미리'\n",
            "filename: '82.jpg', confidence: 0.6841, string: '느'\n",
            "filename: '82.jpg', confidence: 0.1358, string: '어'\n",
            "filename: '82.jpg', confidence: 0.5883, string: '리요'\n",
            "filename: '83.jpg', confidence: 0.2000, string: '한량운누'\n",
            "filename: '84.jpg', confidence: 0.0946, string: '무릎워'\n",
            "filename: '85.jpg', confidence: 0.3437, string: '젠소'\n",
            "filename: '86.jpg', confidence: 0.0481, string: '''\n",
            "filename: '87.jpg', confidence: 0.0153, string: '웨검말트'\n",
            "filename: '88.jpg', confidence: 0.3011, string: '악흐'\n",
            "filename: '89.jpg', confidence: 0.7828, string: '1|'\n",
            "filename: '89.jpg', confidence: 0.5559, string: '화생든'\n",
            "filename: '90.jpg', confidence: 0.5648, string: '바'\n",
            "filename: '90.jpg', confidence: 0.8958, string: '제'\n",
            "filename: '91.jpg', confidence: 0.0000, string: ''\n",
            "filename: '91.jpg', confidence: 0.0208, string: '젠4'\n",
            "filename: '92.jpg', confidence: 0.1364, string: '야월'\n",
            "filename: '93.jpg', confidence: 0.4179, string: '미상'\n",
            "filename: '94.jpg', confidence: 0.2424, string: '쌍이'\n",
            "filename: '95.jpg', confidence: 0.2638, string: '나타날'\n",
            "filename: '96.jpg', confidence: 0.2130, string: '-가악'\n",
            "filename: '97.jpg', confidence: 0.2068, string: '싱익히세요'\n",
            "filename: '98.jpg', confidence: 0.4614, string: '드'\n",
            "filename: '99.jpg', confidence: 0.0578, string: '와이익_'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2955, string: '복악안내'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0185, string: '빼얗'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0232, string: '서율홀바르경히워'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1673, string: '핸일해'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1868, string: '발행가'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2016, string: '뀌'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1489, string: '그므'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1548, string: '꺼'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9276, string: '여'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0319, string: '24년일'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0106, string: '깨빠훨'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0491, string: '환자쟁'\n",
            "filename: 'Text Detection.jpg', confidence: 0.3927, string: '죄자'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9701, string: '3'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2235, string: '야'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1819, string: '공부'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5981, string: 'g680'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0596, string: '있'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0727, string: '1일'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1440, string: '괴'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2400, string: '알'\n",
            "filename: 'Text Detection.jpg', confidence: 0.8869, string: '아침'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9070, string: '점'\n",
            "filename: 'Text Detection.jpg', confidence: 0.7819, string: '제녁'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2935, string: '깨'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9851, string: '포'\n",
            "filename: 'Text Detection.jpg', confidence: 0.6282, string: '저'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0407, string: '식전교'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0291, string: '함'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0745, string: '취침전'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0123, string: '랑켓지혜'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9616, string: '약'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1197, string: '소임진튼제'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1397, string: '2끼'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2228, string: '열진등스임'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5645, string: '워기나'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9466, string: '있요'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5726, string: '임신부'\n",
            "filename: 'Text Detection.jpg', confidence: 0.6944, string: '임신계획미'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1738, string: '2츠'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0282, string: '있 떠O미장렉하'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1469, string: '예니-'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2209, string: '악효'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0524, string: '균이웬'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2187, string: '끌격근빼제'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0238, string: '즐음이률수있문전 기계조각주익하세요'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0109, string: '튜내간들안기능깐큼헤'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1630, string: '기'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0261, string: '츠0-.21657'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0086, string: '라펴쟁낌'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1251, string: '악휴'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1701, string: '쓰성물계'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0371, string: '은'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1018, string: '신로 '\n",
            "filename: 'Text Detection.jpg', confidence: 0.0123, string: '[따젯스생'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0249, string: '괴도듬주니 윽연은위개베'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1357, string: '갇렁애또는'\n",
            "filename: 'Text Detection.jpg', confidence: 0.7046, string: '시즈'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0316, string: '안빵증'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1479, string: '봉제'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0308, string: '떠렌가전무까에가'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9003, string: '미리'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1380, string: '릭'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0580, string: '핸사랑안누리악국'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0196, string: '무맺미젠소'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1657, string: '악히'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0685, string: '위검막흐'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9268, string: '한일해'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5498, string: '화생앙몽'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0074, string: '이생갛내다널 경우전문광워상휘하세요'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0624, string: '늦'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0339, string: '프'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0205, string: '껴'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0209, string: '본안익앗은다른싸워꾸갇복해지마세요'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0846, string: '트랑:'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0001, string: '저방빼로약후듬두웨깨콩질빼랫캠기네퓨'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1153, string: '랑껴헤히'\n",
            "filename: 'Text Detection.jpg', confidence: 0.4710, string: '2'\n",
            "filename: 'Text Detection.jpg', confidence: 0.6585, string: '3'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0143, string: '예니제따히'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5468, string: '1오'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9096, string: '3'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0105, string: '라길뤄그'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9751, string: '1오'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2762, string: '3'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1396, string: '무빠히해'\n",
            "filename: 'Text Detection.jpg', confidence: 0.8869, string: '1오'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5299, string: '3'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2665, string: '때표'\n",
            "filename: 'Text Detection.jpg', confidence: 0.5950, string: '히'\n",
            "filename: 'Text Detection.jpg', confidence: 0.3492, string: '밀해'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0559, string: '\"'\n",
            "filename: 'Text Detection.jpg', confidence: 0.6103, string: '한랑'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0448, string: '너 내요'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9686, string: '층'\n",
            "filename: 'Text Detection.jpg', confidence: 0.2376, string: '깎'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0164, string: '0'\n",
            "filename: 'Text Detection.jpg', confidence: 0.6398, string: '캐'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1312, string: '6455'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1062, string: '0077'\n",
            "filename: 'Text Detection.jpg', confidence: 0.9893, string: '5450'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1542, string: 'F싸니'\n",
            "filename: 'Text Detection.jpg', confidence: 0.0037, string: '뻗압'\n",
            "filename: 'Text Detection.jpg', confidence: 0.3472, string: '닥56'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1421, string: '['\n",
            "filename: 'Text Detection.jpg', confidence: 0.0171, string: '메:'\n",
            "filename: 'Text Detection.jpg', confidence: 0.1017, string: '빼와'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 전처리"
      ],
      "metadata": {
        "id": "0uXvL1MNn7TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils.object_detection import non_max_suppression\n",
        "from imutils.perspective import four_point_transform\n",
        "from imutils.contours import sort_contours\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "from scipy.ndimage import label"
      ],
      "metadata": {
        "id": "Qv9lw51xoQxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_contours(img):\n",
        "  blurred = cv2.GaussianBlur(img, (5, 5,), 0)\n",
        "  ret, thr1 = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)\n",
        "  # edged = cv2.Canny(blurred, 74, 200)\n",
        "  # edged = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  # plt.subplot(121),plt.imshow(img)\n",
        "  # plt.subplot(122),plt.imshow(thr1)\n",
        "  # plt.title(\"find_contours\")\n",
        "  # plt.show()\n",
        "  # return gray\n",
        "  return thr1"
      ],
      "metadata": {
        "id": "H-BePxgFoQvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sharpening_img(img):\n",
        "  sharpening_mask1 = np.array([[-2, -2, -2], [-2, 18, -2], [-2, -2, -2]])\n",
        "  sharpening_out1 = cv2.filter2D(img, -1, sharpening_mask1)\n",
        "\n",
        "  # plt.subplot(121),plt.imshow(img)\n",
        "  # plt.subplot(122),plt.imshow(sharpening_out1)\n",
        "  # plt.title(\"sharpening\")\n",
        "  # plt.show()\n",
        "  return sharpening_out1"
      ],
      "metadata": {
        "id": "iq7ddEngocGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_outlines(edged, img):\n",
        "  cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = imutils.grab_contours(cnts)\n",
        "  cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "  roi_list = []\n",
        "  roi_title_list = []\n",
        "\n",
        "  margin = 20\n",
        "  receipt_grouping = img.copy()\n",
        "\n",
        "  for c in cnts:\n",
        "    (x, y, w, h) = cv2.boundingRect(c)\n",
        "    ar = w // float(h)\n",
        "\n",
        "    if ar > 3.0 and ar < 6.5 and (W/2) < x:\n",
        "      color = (0, 255, 0)\n",
        "      roi = img[y - margin:y + h + margin, x - margin:x + w + margin]\n",
        "      roi_list.append(roi)\n",
        "      roi_title_list.append(\"Roi_{}\".format(len(roi_list)))\n",
        "    else:\n",
        "      color = (0, 0, 255)\n",
        "\n",
        "    cv2.rectangle(receipt_grouping, (x - margin, y - margin), (x + w + margin, y + h + margin), color, 2)\n",
        "    cv2.putText(receipt_grouping, \"\".join(str(ar)), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2)\n",
        "\n",
        "  plt_imshow([\"Grouping Image\"], [receipt_grouping], figsize=(16, 10))"
      ],
      "metadata": {
        "id": "-pQzFcW0ob-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denoisiong_img(img):\n",
        "  dst = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
        "\n",
        "  # plt.subplot(121),plt.imshow(img)\n",
        "  # plt.subplot(122),plt.imshow(dst)\n",
        "  # plt.title(\"denoisiong\")\n",
        "  # plt.show()\n",
        "  return dst"
      ],
      "metadata": {
        "id": "4AQE4ypOob8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_imshow(title='image', img=None, figsize=(8 ,5)):\n",
        "  # 그림(figure) 객체를 생성(그림의 크기, 해상도, 배경색 등의 속성을 직접 지정하고 싶을 때 필수 생성-객체 이용해야 함)\n",
        "  #figsize=(8,5) : 가로 8인치 세로 5인치 그림 생성\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "#img : cv2.imread 한 이미지\n",
        "\n",
        "  # 이미지가 여러개 일때\n",
        "    if type(img) == list:\n",
        "      #title이 여러 개면 titles는 곧 title, title이 한 개면 그림마다 해당 title을 가져서 titles = [title, title,...] 중복 리스트\n",
        "        if type(title) == list:\n",
        "            titles = title\n",
        "        else:\n",
        "            titles = []\n",
        "\n",
        "            for i in range(len(img)):\n",
        "                titles.append(title)\n",
        "\n",
        "      #cv2는 이미지를 BGR로 불러오고, plt는 RGB 이미지가 필요함\n",
        "      #리스트 내 모든 이미지에 대해\n",
        "        for i in range(len(img)):\n",
        "          #이미지가 grayscale이면 RGB이미지로 바꾸기\n",
        "            if len(img[i].shape) <= 2:\n",
        "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_GRAY2RGB)\n",
        "          #이미지가 BGR이라면 RGB로 바꾸기\n",
        "            else:\n",
        "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
        "          #plot 여러개 그리기\n",
        "          #subplot(행, 열, 그릴 위치) , imshow -> plot\n",
        "          #아마 plot 쓴 이유는 이미지 여러 개 그리기 위해서인 듯\n",
        "            plt.subplot(1, len(img), i + 1), plt.imshow(rgbImg)\n",
        "            plt.title(titles[i])\n",
        "          #눈금 설정\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "\n",
        "        plt.show()\n",
        "  #이미지 하나일 때\n",
        "    else:\n",
        "        if len(img.shape) < 3:\n",
        "            rgbImg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.imshow(rgbImg)\n",
        "        plt.title(title)\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "        plt.show()\n",
        "\n",
        "def decode_predictions(scores, geometry):\n",
        "  #scores의 크기를 받고 bounding box 사각형을 추출한뒤 confidencs scores에 대응해본다\n",
        "  #scores의 크기\n",
        "  (numRows, numCols) = scores.shape[2:4]\n",
        "  rects = []\n",
        "  confidences = []\n",
        "\n",
        "  for y in range(0, numRows):\n",
        "    scoresData = scores[0, 0, y]\n",
        "    xData0 = geometry[0, 0, y]\n",
        "    xData1 = geometry[0, 1, y]\n",
        "    xData2 = geometry[0, 2, y]\n",
        "    xData3 = geometry[0, 3, y]\n",
        "    anglesData = geometry[0, 4, y]\n",
        "\n",
        "    for x in range(0, numCols):\n",
        "      #기준 확률보다 작을 경우 박스 버리기\n",
        "      if scoresData[x] < min_confidence:\n",
        "        continue\n",
        "\n",
        "\n",
        "      (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
        "     # prediciton에 대한 회전각을 구하고 sin,cosine을 계산한다\n",
        "     # 글씨가 회전되어 있을때를 대비\n",
        "      angle = anglesData[x]\n",
        "      cos = np.cos(angle)\n",
        "      sin = np.sin(angle)\n",
        "\n",
        "      h = xData0[x] + xData2[x]\n",
        "      w = xData1[x] + xData3[x]\n",
        "\n",
        "      endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
        "      endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
        "      startX = int(endX - w)\n",
        "      startY = int(endY - h)\n",
        "\n",
        "      rects.append((startX, startY, endX, endY))\n",
        "      confidences.append(scoresData[x])\n",
        "\n",
        "  return (rects, confidences)"
      ],
      "metadata": {
        "id": "luBaWy9boQso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 640\n",
        "height = 640\n",
        "min_confidence = 0.5\n",
        "padding = 0.0"
      ],
      "metadata": {
        "id": "QvNviN11oQnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(folder, file):\n",
        "  path = os.path.join(folder, file)\n",
        "  org_image = cv2.imread(path)\n",
        "\n",
        "  # plt_imshow(\"Original\", org_image)\n",
        "\n",
        "  return org_image"
      ],
      "metadata": {
        "id": "QUZglZX3oQb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"/content/EasyOCR/newExamples\"\n",
        "folder = \"/content/drive/MyDrive/Colab Notebooks/workspace/pre_examples\""
      ],
      "metadata": {
        "id": "av6hAa5XoAiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(folder)\n",
        "\n",
        "for file in files:\n",
        "  print(file)\n",
        "  #read_file로 이미지 생성해서 array로 받아오기 / url or file path\n",
        "  img = load_file(folder, file)\n",
        "  org_image = resize_img(img)\n",
        "  org_image = find_contours(org_image)\n",
        "  # # find_outlinaes(org_image, img)\n",
        "  # org_image = denoisiong_img(org_image)\n",
        "  org_image = sharpening_img(org_image)\n",
        "  cv2.imwrite(f\"./preprocessedData/{file}\", org_image)\n",
        "  print(org_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dxS4sRnpUyj",
        "outputId": "05a2300f-d586-4c09-b323-7b3bcd4afb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KakaoTalk_20240413_184140770.jpg\n",
            "(1578, 2102)\n",
            "(6312, 8408)\n",
            "KakaoTalk_20240421_143645255.jpg\n",
            "(3029, 2939)\n",
            "(12116, 11756)\n",
            "KakaoTalk_20240421_143618939_03.jpg\n",
            "(720, 1280)\n",
            "(2880, 5120)\n",
            "KakaoTalk_20240501_200012369.jpg\n",
            "(3024, 4032)\n",
            "(12096, 16128)\n",
            "KakaoTalk_20240430_145159867.jpg\n",
            "(1490, 2220)\n",
            "(5960, 8880)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_img(img):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  print(gray.shape)\n",
        "  resized = cv2.resize(gray, (gray.shape[1]*4,gray.shape[0]*4))\n",
        "  kernel1 = np.ones((5,5), np.uint8)\n",
        "  kernel2 = np.ones((3,3), np.uint8)\n",
        "\n",
        "  dilated = cv2.dilate(resized, kernel1, iterations=1)\n",
        "  dilated = cv2.erode(dilated, kernel2, iterations=1)\n",
        "  # print(dilated.shape)\n",
        "  morph1 = cv2.morphologyEx(dilated, cv2.MORPH_OPEN, kernel2)\n",
        "  morph2 = cv2.morphologyEx(morph1, cv2.MORPH_CLOSE, kernel1)\n",
        "  # plt.subplot(221),plt.imshow(img)\n",
        "  # plt.subplot(222),plt.imshow(dilated)\n",
        "  # plt.subplot(223),plt.imshow(morph1)\n",
        "  # plt.subplot(224),plt.imshow(morph2)\n",
        "\n",
        "  # plt.title(\"resizing\")\n",
        "  # plt.show()\n",
        "  return morph1"
      ],
      "metadata": {
        "id": "FHI1wLWFkEf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRIDso9gWNBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from imutils.object_detection import non_max_suppression\n",
        "import argparse\n",
        "import time\n",
        "import cv2\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 이미지 불러오기\n",
        "image = cv2.imread(\"/content/EasyOCR/preprocessedData/KakaoTalk_20240413_184140770.jpg\")\n",
        "orig = image.copy()\n",
        "(H, W) = image.shape[:2]\n",
        "\n",
        "# 이미지 resize\n",
        "(newW, newH) = (1280, 1280)\n",
        "rW = W / float(newW)\n",
        "rH = H / float(newH)\n",
        "\n",
        "image = cv2.resize(image, (newW, newH))\n",
        "(H, W) = image.shape[:2]\n",
        "\n",
        "#로딩 east 모델\n",
        "layerNames = [\n",
        "    \"feature_fusion/Conv_7/Sigmoid\",\n",
        "    \"feature_fusion/concat_3\"]\n",
        "\n",
        "print(\"[INFO] loading EAST text detector...\")\n",
        "net = cv2.dnn.readNet(\"/content/drive/MyDrive/Colab Notebooks/workspace/pre_trained_model/frozen_east_text_detection.pb\")\n",
        "\n",
        "# net 입력 위해 blob 객체로 변경\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
        "                             (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
        "\n",
        "# net 입력\n",
        "net.setInput(blob)\n",
        "# 학습 결과\n",
        "(scores, geometry) = net.forward(layerNames)\n",
        "\n",
        "#confidence scores\n",
        "(numRows, numCols) = scores.shape[2:4]\n",
        "rects = []\n",
        "confidences = []\n",
        "\n",
        "for y in range(0, numRows):\n",
        "    # extract the scores (probabilities), followed by the geometrical\n",
        "    # data used to derive potential bounding box coordinates that\n",
        "    # surround text\n",
        "    scoresData = scores[0, 0, y]\n",
        "    xData0 = geometry[0, 0, y]\n",
        "    xData1 = geometry[0, 1, y]\n",
        "    xData2 = geometry[0, 2, y]\n",
        "    xData3 = geometry[0, 3, y]\n",
        "    anglesData = geometry[0, 4, y]\n",
        "\n",
        "    for x in range(0, numCols):\n",
        "        # if our score does not have sufficient probability, ignore it\n",
        "        if scoresData[x] < 0.5:\n",
        "            continue\n",
        "\n",
        "        # compute the offset factor as our resulting feature maps will\n",
        "        # be 4x smaller than the input image\n",
        "        (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
        "\n",
        "        # extract the rotation angle for the prediction and then\n",
        "        # compute the sin and cosine\n",
        "        angle = anglesData[x]\n",
        "        cos = np.cos(angle)\n",
        "        sin = np.sin(angle)\n",
        "\n",
        "        # use the geometry volume to derive the width and height of\n",
        "        # the bounding box\n",
        "        h = xData0[x] + xData2[x]\n",
        "        w = xData1[x] + xData3[x]\n",
        "\n",
        "        # compute both the starting and ending (x, y)-coordinates for\n",
        "        # the text prediction bounding box\n",
        "        endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
        "        endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
        "        startX = int(endX - w)\n",
        "        startY = int(endY - h)\n",
        "\n",
        "        # add the bounding box coordinates and probability score to\n",
        "        # our respective lists\n",
        "        rects.append((startX, startY, endX, endY))\n",
        "        confidences.append(scoresData[x])\n",
        "\n",
        "# apply non-maxima suppression to suppress weak, overlapping bounding\n",
        "# boxes\n",
        "boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
        "\n",
        "count = 1\n",
        "# change box width and height -> positive will add pixels and vice-versa\n",
        "box_width_padding = 40\n",
        "box_height_padding = 40\n",
        "\n",
        "temp_image = orig.copy()\n",
        "\n",
        "# delete output folder\n",
        "try:\n",
        "    shutil.rmtree('output')\n",
        "except Exception as e:\n",
        "    do = \"nothing\"\n",
        "print(\"!!\")\n",
        "# create empty output folder\n",
        "uncreated = 1\n",
        "while (uncreated):\n",
        "    try:\n",
        "        os.mkdir('output')\n",
        "        print(\"!\")\n",
        "        uncreated = 0\n",
        "    except Exception as e:\n",
        "        do = \"nothing\"\n",
        "\n",
        "# define crop object\n",
        "class Crop(object):\n",
        "    def __init__(self, startX, startY, endX, endY):\n",
        "        self.startX = startX\n",
        "        self.startY = startY\n",
        "        self.endX = endX\n",
        "        self.endY = endY\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        diff = abs(self.startY - other.startY)\n",
        "        if (diff <= 10):\n",
        "            return self.startX == other.startX\n",
        "        else:\n",
        "            False\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        diff = abs(self.startY - other.startY)\n",
        "        if (diff <= 10):\n",
        "            return self.startX < other.startX\n",
        "        else:\n",
        "            return self.startY < other.startY\n",
        "\n",
        "croppedList = []\n",
        "\n",
        "# loop over the bounding boxes\n",
        "for (startX, startY, endX, endY) in boxes:\n",
        "    # scale the bounding box coordinates based on the respective\n",
        "    # ratios\n",
        "    startX = int(startX * rW) - box_width_padding\n",
        "    startY = int(startY * rH) - box_height_padding\n",
        "    endX = int(endX * rW) + box_width_padding\n",
        "    endY = int(endY * rH) + box_height_padding\n",
        "\n",
        "    # draw the bounding box on the image\n",
        "    cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "\n",
        "    # append to croppedList to sort the images\n",
        "    croppedList.append(Crop(startX, startY, endX, endY))\n",
        "\n",
        "croppedList = sorted(croppedList)\n",
        "\n",
        "for img in croppedList:\n",
        "    roi = temp_image[img.startY:img.endY, img.startX:img.endX]\n",
        "    cv2.imwrite(\"output/\" + str(count) + \".jpg\", roi)\n",
        "    count = count + 1\n",
        "    print(count)\n",
        "\n",
        "# show the output image\n",
        "cv2.imwrite(\"output/Text Detection.jpg\", orig)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wajNTF2tn7AW",
        "outputId": "0074d4f1-2be6-40e2-e832-71d5cf3b642b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'copy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8aa9eb2a897c>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 이미지 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/workspace/pre_examples/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l7AkajKWn-Sx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}